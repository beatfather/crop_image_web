{"ast":null,"code":"import { makeAutoObservable } from 'mobx';\nimport { history, setToken, getToken, removeToken } from '@/utils';\nimport * as openai from 'openai'; // 导入openai库\n\nclass ApiStore {\n  constructor() {\n    var _this = this;\n    this.apiKey = getToken() || '';\n    this.selectedModel = localStorage.getItem('selectedModel') || 'gpt-3.5-turbo';\n    this.setApiKey = apiKey => {\n      console.log(apiKey);\n      this.apiKey = apiKey;\n      setToken(apiKey);\n    };\n    this.getApiKey = () => {\n      return this.apiKey;\n    };\n    this.removeApiKey = () => {\n      this.apiKey = '';\n      removeToken();\n      history.push('/login');\n    };\n    this.setSelectedModel = model => {\n      this.selectedModel = model;\n      localStorage.setItem('selectedModel', model);\n    };\n    this.getSelectedModel = () => {\n      return this.selectedModel;\n    };\n    this.validateApiKeyWithModel = async function () {\n      let modelName = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : 'text-davinci-003';\n      try {\n        const response = await fetch(`https://api.openai.com/v1/engines/${modelName}/completions`, {\n          method: 'POST',\n          headers: {\n            'Content-Type': 'application/json',\n            'Authorization': `Bearer ${_this.apiKey}`\n          },\n          body: JSON.stringify({\n            prompt: '测试 API Key...',\n            max_tokens: 5\n          })\n        });\n        return response.status === 200;\n      } catch (error) {\n        console.error(error);\n        return false;\n      }\n    };\n    this.callGPT = async (prompt, model) => {\n      try {\n        const response = await fetch(`https://api.openai.com/v1/chat/completions`, {\n          method: 'POST',\n          headers: {\n            'Content-Type': 'application/json',\n            'Authorization': `Bearer ${this.apiKey}`\n          },\n          body: JSON.stringify({\n            model: model,\n            // 添加模型参数\n            messages: [{\n              role: \"user\",\n              content: prompt\n            }],\n            max_tokens: 1\n          })\n        });\n        if (response.status === 200) {\n          return true;\n        } else {\n          throw new Error(`Error: ${response.status} ${response.statusText}`);\n        }\n      } catch (error) {\n        console.error(error);\n        return false;\n      }\n    };\n    makeAutoObservable(this);\n  }\n}\nexport default ApiStore;","map":{"version":3,"names":["makeAutoObservable","history","setToken","getToken","removeToken","openai","ApiStore","constructor","_this","apiKey","selectedModel","localStorage","getItem","setApiKey","console","log","getApiKey","removeApiKey","push","setSelectedModel","model","setItem","getSelectedModel","validateApiKeyWithModel","modelName","arguments","length","undefined","response","fetch","method","headers","body","JSON","stringify","prompt","max_tokens","status","error","callGPT","messages","role","content","Error","statusText"],"sources":["C:/Users/94272/Desktop/Job/my-personal_website/beattather/src/store/api.Store.js"],"sourcesContent":["import { makeAutoObservable } from 'mobx';\r\nimport { history, setToken, getToken, removeToken } from '@/utils';\r\nimport * as openai from 'openai'; // 导入openai库\r\n\r\nclass ApiStore {\r\n  apiKey = getToken() || '';\r\n  selectedModel = localStorage.getItem('selectedModel') || 'gpt-3.5-turbo';\r\n\r\n  constructor() {\r\n    makeAutoObservable(this);\r\n  }\r\n\r\n  setApiKey = (apiKey) => {\r\n    console.log(apiKey);\r\n    this.apiKey = apiKey;\r\n    setToken(apiKey);\r\n  };\r\n\r\n  getApiKey = () => {\r\n    return this.apiKey;\r\n  };\r\n\r\n  removeApiKey = () => {\r\n    this.apiKey = '';\r\n    removeToken();\r\n    history.push('/login');\r\n  };\r\n\r\n  setSelectedModel = (model) => {\r\n    this.selectedModel = model;\r\n    localStorage.setItem('selectedModel', model);\r\n  };\r\n\r\n  getSelectedModel = () => {\r\n    return this.selectedModel;\r\n  };\r\n\r\n  validateApiKeyWithModel = async ( modelName = 'text-davinci-003') => {\r\n    try {\r\n      const response = await fetch(`https://api.openai.com/v1/engines/${modelName}/completions`, {\r\n        method: 'POST',\r\n        headers: {\r\n          'Content-Type': 'application/json',\r\n          'Authorization': `Bearer ${this.apiKey}`,\r\n        },\r\n        body: JSON.stringify({\r\n          prompt: '测试 API Key...',\r\n          max_tokens: 5,\r\n        }),\r\n        \r\n      });\r\n\r\n      return response.status === 200;\r\n    } catch (error) {\r\n      console.error(error);\r\n      return false;\r\n    }\r\n  };\r\n\r\n  callGPT = async (prompt : 'test', model:'gpt-4') => {\r\n    try {\r\n      const response = await fetch(`https://api.openai.com/v1/chat/completions`, {\r\n        method: 'POST',\r\n        headers: {\r\n          'Content-Type': 'application/json',\r\n          'Authorization': `Bearer ${this.apiKey}`,\r\n        },\r\n        body: JSON.stringify({\r\n          model: model, // 添加模型参数\r\n          messages: [\r\n            { role: \"user\", content: prompt },\r\n          ],\r\n          max_tokens: 1,\r\n        }),\r\n      });\r\n\r\n      if (response.status === 200) {\r\n        \r\n        return true;\r\n      } else {\r\n        throw new Error(`Error: ${response.status} ${response.statusText}`);\r\n      }\r\n    } catch (error) {\r\n      console.error(error);\r\n\r\n      return false;\r\n    }\r\n  };\r\n}\r\n\r\nexport default ApiStore;"],"mappings":"AAAA,SAASA,kBAAkB,QAAQ,MAAM;AACzC,SAASC,OAAO,EAAEC,QAAQ,EAAEC,QAAQ,EAAEC,WAAW,QAAQ,SAAS;AAClE,OAAO,KAAKC,MAAM,MAAM,QAAQ,CAAC,CAAC;;AAElC,MAAMC,QAAQ,CAAC;EAIbC,WAAWA,CAAA,EAAG;IAAA,IAAAC,KAAA;IAAA,KAHdC,MAAM,GAAGN,QAAQ,EAAE,IAAI,EAAE;IAAA,KACzBO,aAAa,GAAGC,YAAY,CAACC,OAAO,CAAC,eAAe,CAAC,IAAI,eAAe;IAAA,KAMxEC,SAAS,GAAIJ,MAAM,IAAK;MACtBK,OAAO,CAACC,GAAG,CAACN,MAAM,CAAC;MACnB,IAAI,CAACA,MAAM,GAAGA,MAAM;MACpBP,QAAQ,CAACO,MAAM,CAAC;IAClB,CAAC;IAAA,KAEDO,SAAS,GAAG,MAAM;MAChB,OAAO,IAAI,CAACP,MAAM;IACpB,CAAC;IAAA,KAEDQ,YAAY,GAAG,MAAM;MACnB,IAAI,CAACR,MAAM,GAAG,EAAE;MAChBL,WAAW,EAAE;MACbH,OAAO,CAACiB,IAAI,CAAC,QAAQ,CAAC;IACxB,CAAC;IAAA,KAEDC,gBAAgB,GAAIC,KAAK,IAAK;MAC5B,IAAI,CAACV,aAAa,GAAGU,KAAK;MAC1BT,YAAY,CAACU,OAAO,CAAC,eAAe,EAAED,KAAK,CAAC;IAC9C,CAAC;IAAA,KAEDE,gBAAgB,GAAG,MAAM;MACvB,OAAO,IAAI,CAACZ,aAAa;IAC3B,CAAC;IAAA,KAEDa,uBAAuB,GAAG,kBAA2C;MAAA,IAAnCC,SAAS,GAAAC,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAG,kBAAkB;MAC9D,IAAI;QACF,MAAMG,QAAQ,GAAG,MAAMC,KAAK,CAAE,qCAAoCL,SAAU,cAAa,EAAE;UACzFM,MAAM,EAAE,MAAM;UACdC,OAAO,EAAE;YACP,cAAc,EAAE,kBAAkB;YAClC,eAAe,EAAG,UAASvB,KAAI,CAACC,MAAO;UACzC,CAAC;UACDuB,IAAI,EAAEC,IAAI,CAACC,SAAS,CAAC;YACnBC,MAAM,EAAE,eAAe;YACvBC,UAAU,EAAE;UACd,CAAC;QAEH,CAAC,CAAC;QAEF,OAAOR,QAAQ,CAACS,MAAM,KAAK,GAAG;MAChC,CAAC,CAAC,OAAOC,KAAK,EAAE;QACdxB,OAAO,CAACwB,KAAK,CAACA,KAAK,CAAC;QACpB,OAAO,KAAK;MACd;IACF,CAAC;IAAA,KAEDC,OAAO,GAAG,OAAOJ,MAAe,EAAEf,KAAa,KAAK;MAClD,IAAI;QACF,MAAMQ,QAAQ,GAAG,MAAMC,KAAK,CAAE,4CAA2C,EAAE;UACzEC,MAAM,EAAE,MAAM;UACdC,OAAO,EAAE;YACP,cAAc,EAAE,kBAAkB;YAClC,eAAe,EAAG,UAAS,IAAI,CAACtB,MAAO;UACzC,CAAC;UACDuB,IAAI,EAAEC,IAAI,CAACC,SAAS,CAAC;YACnBd,KAAK,EAAEA,KAAK;YAAE;YACdoB,QAAQ,EAAE,CACR;cAAEC,IAAI,EAAE,MAAM;cAAEC,OAAO,EAAEP;YAAO,CAAC,CAClC;YACDC,UAAU,EAAE;UACd,CAAC;QACH,CAAC,CAAC;QAEF,IAAIR,QAAQ,CAACS,MAAM,KAAK,GAAG,EAAE;UAE3B,OAAO,IAAI;QACb,CAAC,MAAM;UACL,MAAM,IAAIM,KAAK,CAAE,UAASf,QAAQ,CAACS,MAAO,IAAGT,QAAQ,CAACgB,UAAW,EAAC,CAAC;QACrE;MACF,CAAC,CAAC,OAAON,KAAK,EAAE;QACdxB,OAAO,CAACwB,KAAK,CAACA,KAAK,CAAC;QAEpB,OAAO,KAAK;MACd;IACF,CAAC;IA9ECtC,kBAAkB,CAAC,IAAI,CAAC;EAC1B;AA8EF;AAEA,eAAeM,QAAQ"},"metadata":{},"sourceType":"module","externalDependencies":[]}